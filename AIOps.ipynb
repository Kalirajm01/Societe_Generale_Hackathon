{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NS05tP37sjuI",
        "outputId": "b2a94ad2-7a6f-435e-c97b-502f1e01c7ea"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "     asset_id       name     type          status     location  \\\n",
            "0  ASSET_9534  Asset_942  Desktop          Active   Location_7   \n",
            "1  ASSET_8877  Asset_817   Laptop  Decommissioned   Location_1   \n",
            "2  ASSET_2015  Asset_270  Desktop          Active  Location_12   \n",
            "3  ASSET_2688  Asset_719   Laptop        Inactive  Location_17   \n",
            "4  ASSET_5667  Asset_773  Desktop  Decommissioned  Location_14   \n",
            "\n",
            "  last_maintenance next_maintenance  \n",
            "0       2023-10-26       2024-07-26  \n",
            "1       2024-04-07       2024-11-05  \n",
            "2       2023-11-11       2024-11-26  \n",
            "3       2023-11-20       2025-05-07  \n",
            "4       2023-09-21       2024-08-08  \n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Read CSV file into a pandas DataFrame\n",
        "assets_df = pd.read_csv('/content/drive/MyDrive/Soc_Gen_Hackatho/assets.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(assets_df.head())"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import csv\n",
        "from datetime import datetime, timedelta\n",
        "import random\n",
        "\n",
        "# Function to generate random server metrics data\n",
        "def generate_server_metrics(start_time, end_time, interval_minutes):\n",
        "    current_time = start_time\n",
        "    data = []\n",
        "\n",
        "    while current_time <= end_time:\n",
        "        cpu_usage = round(random.uniform(40.0, 80.0), 2)\n",
        "        memory_usage = round(random.uniform(50.0, 90.0), 2)\n",
        "        disk_usage = round(random.uniform(60.0, 95.0), 2)\n",
        "        data.append([current_time.strftime('%Y-%m-%d %H:%M:%S'), cpu_usage, memory_usage, disk_usage])\n",
        "        current_time += timedelta(minutes=interval_minutes)\n",
        "\n",
        "    return data\n",
        "\n",
        "# Define the start and end time for the data\n",
        "start_time = datetime(2024, 7, 14, 0, 0, 0)\n",
        "end_time = datetime(2024, 7, 14, 23, 59, 59)\n",
        "interval_minutes = 30  # Interval of 1 hour\n",
        "\n",
        "# Generate the data\n",
        "server_metrics = generate_server_metrics(start_time, end_time, interval_minutes)\n",
        "\n",
        "# Define the header\n",
        "header = ['timestamp', 'cpu_usage', 'memory_usage', 'disk_usage']\n",
        "\n",
        "# Write the data to a CSV file\n",
        "with open('server_metrics.csv', 'w', newline='') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(header)\n",
        "    writer.writerows(server_metrics)\n",
        "\n",
        "print(\"server_metrics.csv file has been generated.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-kabb5a5XsqU",
        "outputId": "02838659-eb37-4489-faf4-8d7cbe85b2ce"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "server_metrics.csv file has been generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate_software_inventory.py\n",
        "\n",
        "import csv\n",
        "\n",
        "software_inventory = [\n",
        "    {\"software_id\": 1, \"software_name\": \"Operating System X\", \"version\": \"10.0\", \"license_status\": \"Licensed\"},\n",
        "    {\"software_id\": 2, \"software_name\": \"Antivirus Y\", \"version\": \"5.2\", \"license_status\": \"Trial\"},\n",
        "    {\"software_id\": 3, \"software_name\": \"Office Suite Z\", \"version\": \"3.1\", \"license_status\": \"Licensed\"},\n",
        "    # Add more records as needed\n",
        "]\n",
        "\n",
        "with open('software_inventory.csv', 'w', newline='') as file:\n",
        "    writer = csv.DictWriter(file, fieldnames=software_inventory[0].keys())\n",
        "    writer.writeheader()\n",
        "    writer.writerows(software_inventory)\n",
        "\n",
        "print(\"software_inventory.csv file has been generated.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XGLWV3UsZSMw",
        "outputId": "615eb4d8-dd97-43c9-b133-df8b7c4438bf"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "software_inventory.csv file has been generated.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import random\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Generate random asset data\n",
        "asset_types = ['Server', 'Switch', 'Laptop', 'Router']\n",
        "locations = ['Data Center A', 'Office Building B', 'Remote Site C']\n",
        "statuses = ['Operational', 'Under Maintenance', 'Decommissioned']\n",
        "\n",
        "num_assets = 100  # Number of assets to generate\n",
        "data = []\n",
        "\n",
        "for _ in range(num_assets):\n",
        "    asset_type = random.choice(asset_types)\n",
        "    location = random.choice(locations)\n",
        "    status = random.choice(statuses)\n",
        "    purchase_date = datetime.now() - timedelta(days=random.randint(0, 365*5))  # Random purchase date in the last 5 years\n",
        "    maintenance_count = random.randint(0, 5)\n",
        "\n",
        "    # Generate maintenance history\n",
        "    maintenance_history = []\n",
        "    for _ in range(maintenance_count):\n",
        "        maintenance_date = purchase_date + timedelta(days=random.randint(30, 365))\n",
        "        details = f\"Routine maintenance {random.randint(1, 10)}\"\n",
        "        maintenance_history.append({'date': maintenance_date.strftime('%Y-%m-%d'), 'details': details})\n",
        "\n",
        "    asset_data = {\n",
        "        'AssetType': asset_type,\n",
        "        'Location': location,\n",
        "        'Status': status,\n",
        "        'PurchaseDate': purchase_date.strftime('%Y-%m-%d'),\n",
        "        'MaintenanceHistory': maintenance_history\n",
        "    }\n",
        "    data.append(asset_data)\n",
        "\n",
        "# Convert to DataFrame\n",
        "df = pd.DataFrame(data)\n",
        "df.to_csv('assets_dataset.csv', index=False)\n"
      ],
      "metadata": {
        "id": "02I0vXqj3gp1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from datetime import datetime, timedelta\n",
        "\n",
        "# Function to generate a date range\n",
        "def generate_date_range(start_date, periods, freq):\n",
        "    return pd.date_range(start=start_date, periods=periods, freq=freq)\n",
        "\n",
        "# Generate Server Metrics Dataset\n",
        "def generate_server_metrics(start_date, periods):\n",
        "    date_range = generate_date_range(start_date, periods, 'T')  # 'T' for minute frequency\n",
        "    server_metrics = pd.DataFrame({\n",
        "        'timestamp': date_range,\n",
        "        'server_id': ['server01'] * periods,\n",
        "        'cpu_usage': np.random.uniform(50, 100, periods),\n",
        "        'memory_usage': np.random.uniform(50, 100, periods),\n",
        "        'disk_usage': np.random.uniform(50, 100, periods),\n",
        "        'uptime': np.random.randint(1000, 10000, periods),\n",
        "        'error_rate': np.random.randint(0, 10, periods)\n",
        "    })\n",
        "    server_metrics.to_csv('server_metrics.csv', index=False)\n",
        "\n",
        "# Generate Application Performance Dataset\n",
        "def generate_application_performance(start_date, periods):\n",
        "    date_range = generate_date_range(start_date, periods, 'T')\n",
        "    application_performance = pd.DataFrame({\n",
        "        'timestamp': date_range,\n",
        "        'application_id': ['app01'] * periods,\n",
        "        'response_time': np.random.uniform(100, 300, periods),\n",
        "        'request_count': np.random.randint(100, 500, periods),\n",
        "        'error_count': np.random.randint(0, 10, periods)\n",
        "    })\n",
        "    application_performance.to_csv('application_performance.csv', index=False)\n",
        "\n",
        "# Generate Hardware Inventory Dataset\n",
        "def generate_hardware_inventory():\n",
        "    hardware_inventory = pd.DataFrame({\n",
        "        'asset_id': ['asset01', 'asset02'],\n",
        "        'type': ['server', 'workstation'],\n",
        "        'manufacturer': ['Dell', 'HP'],\n",
        "        'model': ['R720', 'Z420'],\n",
        "        'serial_number': ['SN12345', 'SN67890'],\n",
        "        'purchase_date': ['2022-01-15', '2021-03-10'],\n",
        "        'warranty_expiry_date': ['2025-01-15', '2024-03-10'],\n",
        "        'status': ['in use', 'under maintenance']\n",
        "    })\n",
        "    hardware_inventory.to_csv('hardware_inventory.csv', index=False)\n",
        "\n",
        "# Generate Software Inventory Dataset\n",
        "def generate_software_inventory():\n",
        "    software_inventory = pd.DataFrame({\n",
        "        'software_id': ['sw01', 'sw02'],\n",
        "        'name': ['Windows Server', 'Microsoft Office'],\n",
        "        'version': ['2019', '2019'],\n",
        "        'license_key': ['XXXXX-XXXXX-XXXXX-XXXXX', 'YYYYY-YYYYY-YYYYY-YYYYY'],\n",
        "        'installation_date': ['2022-01-15', '2021-03-10'],\n",
        "        'expiration_date': ['2025-01-15', '2024-03-10'],\n",
        "        'status': ['active', 'expired']\n",
        "    })\n",
        "    software_inventory.to_csv('software_inventory.csv', index=False)\n",
        "\n",
        "# Generate Network Traffic Dataset\n",
        "def generate_network_traffic(start_date, periods):\n",
        "    date_range = generate_date_range(start_date, periods, 'T')\n",
        "    network_traffic = pd.DataFrame({\n",
        "        'timestamp': date_range,\n",
        "        'device_id': ['router01'] * periods,\n",
        "        'upload_speed': np.random.uniform(50, 150, periods),\n",
        "        'download_speed': np.random.uniform(100, 300, periods),\n",
        "        'packet_loss': np.random.uniform(0, 1, periods),\n",
        "        'latency': np.random.uniform(10, 50, periods)\n",
        "    })\n",
        "    network_traffic.to_csv('network_traffic.csv', index=False)\n",
        "\n",
        "# Generate Device Status Dataset\n",
        "def generate_device_status(start_date, periods):\n",
        "    date_range = generate_date_range(start_date, periods, 'T')\n",
        "    device_status = pd.DataFrame({\n",
        "        'timestamp': date_range,\n",
        "        'device_id': ['switch01'] * periods,\n",
        "        'status': np.random.choice(['online', 'offline', 'degraded'], periods),\n",
        "        'uptime': np.random.randint(1000, 10000, periods),\n",
        "        'error_count': np.random.randint(0, 10, periods)\n",
        "    })\n",
        "    device_status.to_csv('device_status.csv', index=False)\n",
        "\n",
        "# Generate all datasets\n",
        "start_date = datetime.now()\n",
        "periods = 60  # Number of periods (minutes)\n",
        "\n",
        "generate_server_metrics(start_date, periods)\n",
        "generate_application_performance(start_date, periods)\n",
        "generate_hardware_inventory()\n",
        "generate_software_inventory()\n",
        "generate_network_traffic(start_date, periods)\n",
        "generate_device_status(start_date, periods)\n",
        "\n",
        "print(\"Datasets generated and saved as CSV files.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CujyMkmSvgI",
        "outputId": "87eb5191-071b-423d-99e9-91c95fb2f372"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Datasets generated and saved as CSV files.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Counting assets by type\n",
        "asset_counts = assets_df['type'].value_counts()\n",
        "print(\"Asset Counts by Type:\")\n",
        "print(asset_counts)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrQLD-zotYKI",
        "outputId": "09e22a6c-60e6-49b2-86bc-280d61ab0227"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Asset Counts by Type:\n",
            "type\n",
            "Laptop     76\n",
            "Switch     76\n",
            "Desktop    71\n",
            "Server     70\n",
            "Router     57\n",
            "Name: count, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file into a pandas DataFrame\n",
        "network_df = pd.read_csv('/content/drive/MyDrive/Soc_Gen_Hackatho/network_traffic.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(network_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tOGDTj_4tbgk",
        "outputId": "2cf339b0-3b1c-4a18-ce26-9a6705e677d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             timestamp      source_ip destination_ip  bytes_sent  \\\n",
            "0  2023-01-01 00:00:00  192.168.1.129     10.0.0.207        7504   \n",
            "1  2023-01-01 00:01:00  192.168.1.169     10.0.0.162        3945   \n",
            "2  2023-01-01 00:02:00  192.168.1.169     10.0.0.129        9432   \n",
            "3  2023-01-01 00:03:00   192.168.1.30     10.0.0.181        1020   \n",
            "4  2023-01-01 00:04:00  192.168.1.119     10.0.0.149        4388   \n",
            "\n",
            "   bytes_received  packet_loss  \n",
            "0            2642       0.8746  \n",
            "1            5547       0.5432  \n",
            "2            6515       0.4498  \n",
            "3            9687       0.7713  \n",
            "4            9253       0.9570  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Calculate average bytes sent and received\n",
        "avg_bytes_sent = network_df['bytes_sent'].mean()\n",
        "avg_bytes_received = network_df['bytes_received'].mean()\n",
        "print(f\"Average Bytes Sent: {avg_bytes_sent}\")\n",
        "print(f\"Average Bytes Received: {avg_bytes_received}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H62o38Xttfug",
        "outputId": "78278712-710c-4670-d998-735248060b7c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average Bytes Sent: 5030.4078\n",
            "Average Bytes Received: 5049.0222\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file into a pandas DataFrame\n",
        "performance_df = pd.read_csv('/content/drive/MyDrive/Soc_Gen_Hackatho/performance.csv')\n",
        "\n",
        "# Display the first few rows of the DataFrame to verify\n",
        "print(performance_df.head())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7evzC6Stolv",
        "outputId": "0912c90b-9ce4-4e36-f27e-262004224521"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "             timestamp  cpu_usage  memory_usage  disk_io\n",
            "0  2023-01-01 00:00:00      45.87         71.26    36.11\n",
            "1  2023-01-01 01:00:00      24.54          1.11    63.97\n",
            "2  2023-01-01 02:00:00       5.24         12.21    37.02\n",
            "3  2023-01-01 03:00:00      40.99         93.90    55.86\n",
            "4  2023-01-01 04:00:00      65.39         19.45    21.82\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Example: Calculate average CPU usage\n",
        "avg_cpu_usage = performance_df['cpu_usage'].mean()\n",
        "print(f\"Average CPU Usage: {avg_cpu_usage}\")\n",
        "\n",
        "# Example: Train a simple regression model to predict memory usage\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Prepare data for model training\n",
        "X = performance_df[['cpu_usage', 'disk_io']]\n",
        "y = performance_df['memory_usage']\n",
        "\n",
        "# Train the model\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Predict memory usage for new data\n",
        "new_data = pd.DataFrame({'cpu_usage': [50.0], 'disk_io': [30.0]})\n",
        "predicted_memory_usage = model.predict(new_data)\n",
        "print(f\"Predicted Memory Usage: {predicted_memory_usage}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TwIdD09ltwvP",
        "outputId": "35a96add-2be9-4a50-b151-8ce189eb4f4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average CPU Usage: 49.827275\n",
            "Predicted Memory Usage: [50.39325172]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2VxQQc7p4QkK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# upload_data_to_firebase.py\n",
        "import firebase_admin\n",
        "from firebase_admin import credentials, firestore\n",
        "import pandas as pd\n",
        "\n",
        "# Initialize Firebase\n",
        "cred = credentials.Certificate('/content/drive/MyDrive/Soc_Gen_Hackatho/serviceAccountKey.json')\n",
        "firebase_admin.initialize_app(cred)\n",
        "db = firestore.client()\n",
        "\n",
        "def upload_data(collection_name, data):\n",
        "    collection_ref = db.collection(collection_name)\n",
        "    for _, row in data.iterrows():\n",
        "        collection_ref.add(row.to_dict())\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # Load and preprocess the dataset\n",
        "    dataset = pd.read_csv('/content/drive/MyDrive/Soc_Gen_Hackatho/assets.csv')\n",
        "\n",
        "    # Upload to Firebase\n",
        "    upload_data('synthetic_data', dataset)\n",
        "    print(\"Data uploaded successfully.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wB4DXZ4UudXA",
        "outputId": "1cff5f1a-1cd1-4cc1-b09d-3144d7d23b57"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Data uploaded successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load dataset\n",
        "df = pd.read_csv('assets_dataset.csv')\n",
        "\n",
        "# Feature engineering (example: using maintenance history count as a feature)\n",
        "df['maintenance_count'] = df['MaintenanceHistory'].apply(lambda x: len(eval(x)))\n",
        "\n",
        "# Define features and target\n",
        "X = df[['maintenance_count']]  # Example feature\n",
        "y = df['Status']  # Example target (status)\n",
        "\n",
        "# Split data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train a model (example using Random Forest)\n",
        "model = RandomForestClassifier()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate model performance\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Model Accuracy: {accuracy}')\n",
        "\n",
        "# Example: Save the trained model for future use\n",
        "import joblib\n",
        "joblib.dump(model, 'predictive_model.pkl')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "egtmu0_-4SD_",
        "outputId": "92fe57a9-7ef9-446a-9421-26374c27a973"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 0.25\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['predictive_model.pkl']"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    }
  ]
}